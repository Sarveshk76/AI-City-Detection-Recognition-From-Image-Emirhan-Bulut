# -*- coding: utf-8 -*-
"""AI_City_Detection_Recognition _From_Image_Emirhan_Bulut.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CQFHz5HJ8N7yMLTYybFolMw-6kXaTzMo
"""

!kaggle datasets download -d "ahmedhaytham/where-am-i"

!unzip where-am-i.zip

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory("/content/Data/train",
    labels="inferred",
    label_mode="int",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False)

val_generator = val_datagen.flow_from_directory(
    "/content/Data/Val",
    labels="inferred",
    label_mode="int",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False)

from tensorflow.keras.layers import *
from tensorflow import keras
from tensorflow.keras import Sequential

model = Sequential(name="Emirhan_Sign_Language_Detection_Deep_Learning")

model.add(Conv2D(256,2,2,padding="valid",input_shape=(128,128,1)))
model.add(SpatialDropout2D(0.2))
model.add(MaxPool2D(2))
model.add(Conv2D(256,2,2,padding="valid",input_shape=(128,128,1)))
model.add(SpatialDropout2D(0.2))
model.add(MaxPool2D(2))
model.add(Conv2D(256,2,2,padding="valid",input_shape=(128,128,1)))
model.add(SpatialDropout2D(0.2))
model.add(Conv2D(256,2,2,padding="valid",input_shape=(128,128,1)))
model.add(SpatialDropout2D(0.2))
model.add(LeakyReLU())
model.add(SpatialDropout2D(0.2))
model.add(MaxPool2D(2))
model.add(SpatialDropout2D(0.2))
model.add(Conv2D(512,2,2,padding="valid"))
model.add(Conv2D(512,2,2,padding="valid"))
model.add(SpatialDropout2D(0.2))
model.add(Conv2D(1024,2,2,padding="valid"))
model.add(Conv2D(1024,2,2,padding="valid"))
model.add(Conv2D(1024,2,2,padding="valid"))
model.add(LeakyReLU())
model.add(SpatialDropout2D(0.2))
model.add(Conv2D(2048,2,padding="valid"))
model.add(Conv2D(2048,2,padding="valid"))
model.add(Conv2D(2048,2,padding="valid"))
model.add(Conv2D(2048,2,padding="valid"))
model.add(SpatialDropout2D(0.2))
model.add(Conv2D(1024,2,padding="valid"))
model.add(MaxPool2D(2))
model.add(Conv2D(1024,2,padding="valid"))
model.add(Conv2D(1024,2,padding="valid"))
model.add(MaxPool2D(2))
model.add(Conv2D(1024,2,padding="valid"))
model.add(PReLU())
model.add(SpatialDropout2D(0.2))
model.add(MaxPool2D(3))

model.add(Flatten())

model.add(Dense(64))
model.add(PReLU())
model.add(Dropout(0.2))
model.add(Dense(32))
model.add(PReLU())
model.add(Dropout(0.2))
model.add(Dense(512))
model.add(PReLU())
model.add(Dropout(0.2))
model.add(Dense(3,activation="tanh"))

model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=["accuracy"])

model.fit(train_generator,
          validation_data=val_generator,
          batch_size=256,
          validation_batch_size=128,
          epochs=64,
          shuffle=True,
          callbacks=[keras.callbacks.ModelCheckpoint("/content/model/model_{epoch}.h5")])

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
model = load_model("/content/model/model_8.h5")

from keras.preprocessing.image import ImageDataGenerator

test = ImageDataGenerator(rescale=1./255,horizontal_flip=True,zca_epsilon=99) 
test_generator = test.flow_from_directory("/content/Data/test",
    labels="inferred",
    label_mode="int",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False)

model.evaluate(test_generator)

model.evaluate(val_generator)

model.evaluate(train_generator)

def prediction(data,model):
  pred = model.predict(data)
  if pred[0][0] > pred[0][1] or pred[0][2]:
    print("""Predict Image is Cairo!
  City Recognition Artificial Intelligence Software was developed by Emirhan BULUT.""")
  elif pred[0][1] > pred[0][0] or pred[0][2]:
    print("""Predict Image is Moscow!
  City Recognition Artificial Intelligence Software was developed by Emirhan BULUT.""")
  else:
    print("""Predict Image is Paris!
  City Recognition Artificial Intelligence Software was developed by Emirhan BULUT.""")

from keras.preprocessing.image import ImageDataGenerator

predict = ImageDataGenerator(rescale=1./255,horizontal_flip=True,zca_epsilon=99) 
predict_generator = predict.flow_from_directory(
    "/content/test",
    labels="inferred",
    label_mode="int",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False)

prediction(predict_generator,model)

from PIL import Image
import matplotlib.pyplot as plt
im = Image.open("paris.jpg")
plt.imshow(im)
plt.show()

from keras.preprocessing.image import ImageDataGenerator

predict = ImageDataGenerator(rescale=1./255,horizontal_flip=True,zca_epsilon=99) 
predict_generator = predict.flow_from_directory(
    "/content/test",
    labels="inferred",
    label_mode="int",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False)

prediction(predict_generator,model)

from PIL import Image
import matplotlib.pyplot as plt
im = Image.open("moscow.jpg")
plt.imshow(im)
plt.show()

from keras.preprocessing.image import ImageDataGenerator

predict = ImageDataGenerator(rescale=1./255,horizontal_flip=True,zca_epsilon=99) 
predict_generator = predict.flow_from_directory(
    "/content/test",
    labels="inferred",
    label_mode="int",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False))

prediction(predict_generator,model)

from PIL import Image
import matplotlib.pyplot as plt
im = Image.open("cairo.jpg")
plt.imshow(im)
plt.show()